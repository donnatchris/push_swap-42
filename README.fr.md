##### [üá´üá∑ Version fran√ßaise](README.fr.md) / [üá¨üáß English version](README.md)

# PROJET PUSH_SWAP POUR 42
Par chdonnat (Christophe Donnat de 42 Perpignan, France)

## BUT DU PROJET :

Le projet Push swap est un exercice d'algorithmique simple et efficace :
vous devez trier des donn√©es.
Vous disposez d'un ensemble d'entiers, de deux piles (stacks),
et d'un ensemble d'instructions pour les manipuler.
Votre objectif ? √âcrire un programme en C nomm√© push_swap qui calcule
et affiche sur la sortie standard le plus petit programme,
compos√© d'instructions du langage Push swap, qui trie les entiers pass√©s en param√®tres.

## QUELQUES COMMANDES UTILES :

compiler le programme push_swap

	make

compiler le programme checker

	make bonus

supprimer tous les fichiers .o g√©n√©r√©s par la commande make

	make clean

g√©n√©rer une liste de 500 entiers (sans doublons) s√©par√©s par des espaces
et assigner la liste √† la variable ARG
(vous pouvez choisir un autre nombre comme 100 ou 5 par exemple)
 
	ARG=$(<mettez ici votre liste de nombres √† trier>)

compter le nombre d'√©tapes utilis√©es par push_swap pour trier les nombres dans ARG

	./push_swap "$ARG" | wc -l
 
pour Mac:
v√©rifier la sortie de push_swap en utilisant le testeur de 42 :
renvoie OK si la sortie de push_swap trie les nombres dans ARG
ou renvoie KO sinon
renvoie une erreur s'il y a eu une erreur

	./push_swap "$ARG" | ./tests/checker_Mac "$ARG"

identique √† ci-dessus mais pour linux

	./push_swap "$ARG" | ./tests/checker_linux "$ARG"

identique √† ci-dessus mais en utilisant mon propre testeur (r√©alis√© pour le bonus du projet)

	./push_swap "$ARG" | ./checker "$ARG"

 ---

## √Ä propos de mon algorithme
J'ai utilis√© un algorithme de tri assez standard pour un push_swap (compar√© √† ce que vous trouverez en ligne). Essentiellement, le programme pousse toutes les valeurs √† trier sur la pile B, ne laissant que 3 valeurs sur la pile A, qu'il trie directement.
√Ä partir de l√†, le programme identifie la valeur √† ramener √† la bonne position dans la pile A (similaire au tri par insertion) en choisissant celle qui n√©cessite le moins de mouvements. Il d√©place ensuite cette valeur √† la bonne position dans la pile A et r√©p√®te le processus jusqu'√† ce que la pile B soit vide.
Enfin, il effectue une rotation sur la pile A pour placer la plus petite valeur en haut.

Pour ce projet, j'ai utilis√© deux listes doublement cha√Æn√©es circulaires pour repr√©senter les piles.
Vous trouverez les fonctions pour manipuler ces listes doublement cha√Æn√©es circulaires dans les fichiers dclst.c.

> Si vous souhaitez voir une approche de tri beaucoup plus originale (qui n√©cessite moins de calculs, m√™me si elle demande plus de mouvements), j'ai cod√© un push_swap qui utilise trois fonctions r√©cursives. > Ce fut un v√©ritable casse-t√™te √† mettre en ≈ìuvre, mais le r√©sultat est tr√®s satisfaisant.
> Malheureusement, je n'ai pas utilis√© cette version pour le projet 42 car elle ne permettait pas d'obtenir le meilleur score pour le tri de 100 valeurs.
> Il faut plus de 700 mouvements pour 100 valeurs mais reste en dessous de 5500 mouvements pour 500 valeurs.
> Vous pouvez trouver cet algorithme dans mon autre d√©p√¥t :

[recursive_push_swap.
](https://github.com/donnatchris/recursive_push_swap)

---

## DOCUMENTATION

### Complexit√©

Le concept de complexit√© temporelle fait r√©f√©rence au temps qu'un algorithme met pour s'ex√©cuter en fonction de la taille de l'entr√©e.
Elle est g√©n√©ralement exprim√©e en utilisant la notation Big O, qui fournit une borne sup√©rieure sur le nombre d'op√©rations que l'algorithme effectuera par rapport √† la taille de l'entr√©e.
Cela nous permet d'estimer comment l'algorithme se comportera √† mesure que la taille de l'entr√©e augmente.

Par exemple, un algorithme avec une complexit√© temporelle de O(n) signifie que le nombre d'op√©rations augmentera de mani√®re lin√©aire avec la taille de l'entr√©e.
Un algorithme avec une complexit√© temporelle de O(n^2), comme le tri √† bulles, verra son temps d'ex√©cution augmenter de mani√®re quadratique √† mesure que la taille de l'entr√©e augmente.
L'objectif de la compr√©hension de la complexit√© temporelle est d'√©valuer l'efficacit√© d'un algorithme √† mesure que la taille de l'entr√©e augmente, en particulier lorsqu'il s'agit de grands ensembles de donn√©es.

De m√™me, la complexit√© spatiale fait r√©f√©rence √† la quantit√© de m√©moire qu'un algorithme n√©cessite par rapport √† la taille de l'entr√©e. La complexit√© temporelle et spatiale nous aident √† comprendre l'efficacit√© des algorithmes en termes de calcul et d'utilisation de la m√©moire.

### Algorithmes de tri courants :

#### Tri √† bulles (Bubble Sort):
Le tri √† bulles est un algorithme de tri simple bas√© sur la comparaison.
Il parcourt la liste √† plusieurs reprises, compare les √©l√©ments adjacents et les √©change s'ils sont dans le mauvais ordre.
Ce processus se poursuit jusqu'√† ce qu'aucun √©change ne soit n√©cessaire, ce qui signifie que la liste est tri√©e.
Malgr√© sa simplicit√©, le tri √† bulles est inefficace pour les grands ensembles de donn√©es en raison de sa complexit√© temporelle de O(n^2).

#### Tri par s√©lection (Selection Sort):
Le tri par s√©lection divise la liste en une partie tri√©e et une partie non tri√©e.
Il s√©lectionne √† plusieurs reprises le plus petit (ou le plus grand) √©l√©ment de la partie non tri√©e et l'√©change avec le premier √©l√©ment de la partie non tri√©e,
d√©pla√ßant la fronti√®re entre les deux parties jusqu'√† ce que toute la liste soit tri√©e.
Sa complexit√© temporelle est de O(n^2).

#### Tri par insertion (Insertion Sort):
Le tri par insertion construit la liste tri√©e un √©l√©ment √† la fois.
Il prend chaque √©l√©ment de la partie non tri√©e et l'ins√®re √† la bonne position dans la partie tri√©e en d√©calant les √©l√©ments si n√©cessaire.
Il fonctionne efficacement pour les ensembles de donn√©es petits ou presque tri√©s avec une complexit√© temporelle de O(n^2).

#### Tri fusion (Merge Sort):
Le tri fusion est un algorithme de type "diviser pour r√©gner" qui divise la liste en sous-listes plus petites jusqu'√† ce que chaque sous-liste ne contienne qu'un seul √©l√©ment.
Ensuite, il fusionne ces sous-listes dans l'ordre tri√© pour former la liste tri√©e finale.
Sa complexit√© temporelle est de O(n log n), ce qui le rend efficace pour les grands ensembles de donn√©es.

#### Tri rapide (Quick Sort):
Le tri rapide est √©galement un algorithme de type "diviser pour r√©gner".
Il s√©lectionne un √©l√©ment pivot, partitionne la liste en deux parties (√©l√©ments plus petits que le pivot et √©l√©ments plus grands que le pivot), et trie r√©cursivement les sous-listes.
Sa complexit√© temporelle moyenne est de O(n log n), mais elle peut se d√©grader √† O(n^2) dans le pire des cas.

#### Tri par tas (Heap Sort):
Le tri par tas utilise une structure de donn√©es de tas binaire pour trier la liste.
Il construit un tas max √† partir de l'entr√©e et extrait √† plusieurs reprises le plus grand √©l√©ment, le pla√ßant √† la fin de la liste, puis reconstruit le tas.
Il a une complexit√© temporelle de O(n log n) et est efficace pour les grands ensembles de donn√©es.

#### Tri par comptage (Counting Sort):
Le tri par comptage est un algorithme de tri non bas√© sur la comparaison qui fonctionne bien pour les ensembles de donn√©es d'entiers dans une plage limit√©e.
Il compte les occurrences de chaque √©l√©ment, puis calcule leurs positions dans la liste tri√©e.
Sa complexit√© temporelle est de O(n + k), o√π k est la plage des valeurs d'entr√©e.

#### Tri par base (Radix Sort):
Le tri par base trie les entiers en traitant les chiffres individuels du moins significatif au plus significatif.
Il utilise un algorithme de tri stable comme le tri par comptage pour chaque position de chiffre.
Sa complexit√© temporelle est de O(nk), o√π k est le nombre de chiffres dans le plus grand nombre.